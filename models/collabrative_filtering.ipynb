{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375d4b65-42f8-44e6-a46c-a9113fca88b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with shape: (1000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('collab_dataset.csv')\n",
    "ratings_matrix = data.values\n",
    "\n",
    "# Print dataset shape to verify it's loaded\n",
    "print(f\"Dataset loaded with shape: {ratings_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b7149b-f78f-4e81-a46f-d13fdaad15d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1000, 5000)\n",
      "Validation set size: 1100\n",
      "Test set size: 1100\n"
     ]
    }
   ],
   "source": [
    "# Define the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Prepare training, validation, and test indices\n",
    "non_nan_indices = np.array([(i, j) for i, j in zip(*np.where(~np.isnan(ratings_matrix)))])\n",
    "np.random.shuffle(non_nan_indices)\n",
    "\n",
    "# Split indices (80-10-10)\n",
    "train_size = int(len(non_nan_indices) * 0.8)\n",
    "valid_size = int(len(non_nan_indices) * 0.1)\n",
    "\n",
    "train_indices = non_nan_indices[:train_size]\n",
    "valid_indices = non_nan_indices[train_size:train_size + valid_size]\n",
    "test_indices = non_nan_indices[train_size + valid_size:]\n",
    "\n",
    "# Create matrices with NaNs for splitting data\n",
    "train_matrix = np.full_like(ratings_matrix, np.nan)\n",
    "for i, j in train_indices:\n",
    "    train_matrix[i, j] = ratings_matrix[i, j]\n",
    "\n",
    "# Print the size of each split\n",
    "print(f\"Training set size: {train_matrix.shape}\")\n",
    "print(f\"Validation set size: {len(valid_indices)}\")\n",
    "print(f\"Test set size: {len(test_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603f7867-aa8b-47df-8aa9-e80728bdeaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global mean: 47.8138\n",
      "Shape of filled training matrix: (1000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Global mean for centering\n",
    "global_mean = np.nanmean(train_matrix)\n",
    "train_matrix_filled = np.nan_to_num(train_matrix - global_mean, nan=0)\n",
    "\n",
    "# Print the global mean and the filled training matrix shape\n",
    "print(f\"Global mean: {global_mean:.4f}\")\n",
    "print(f\"Shape of filled training matrix: {train_matrix_filled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a563eeb3-5fd5-48f4-acde-594dce3df580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD-predicted matrix (first 5 rows):\n",
      "[[3.12117695e-02 4.79255563e+01 4.85038186e+01 ... 4.82000189e+01\n",
      "  4.79686139e+01 4.80686615e+01]\n",
      " [4.78297433e+01 4.77391185e+01 4.84881783e+01 ... 4.83612435e+01\n",
      "  4.77062232e+01 4.82696689e+01]\n",
      " [2.03733782e+00 4.76717722e+01 4.87309421e+01 ... 4.77256567e+01\n",
      "  4.73043626e+01 4.74180951e+01]\n",
      " [3.00375180e+00 4.78332579e+01 4.66920078e+01 ... 4.79382555e+01\n",
      "  4.81190305e+01 4.75847470e+01]\n",
      " [4.00588368e+00 4.77860084e+01 4.74092309e+01 ... 4.77394736e+01\n",
      "  4.86148976e+01 4.75260185e+01]]\n"
     ]
    }
   ],
   "source": [
    "# SVD for Latent Factor Model\n",
    "def svd_predict(matrix_filled, n_components=100):\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    svd.fit(matrix_filled)\n",
    "    transformed = svd.transform(matrix_filled)\n",
    "    predicted_matrix = svd.inverse_transform(transformed) + global_mean\n",
    "    return predicted_matrix\n",
    "\n",
    "# SVD-predicted matrix\n",
    "predicted_matrix_svd = svd_predict(train_matrix_filled)\n",
    "\n",
    "# Print a sample of the predicted matrix\n",
    "print(f\"SVD-predicted matrix (first 5 rows):\")\n",
    "print(predicted_matrix_svd[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c16faee-cd1d-463a-84ea-d9e9418f397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-based predicted matrix (first 5 rows):\n",
      "[[0.01881289 0.         0.03733716 ... 0.         0.         0.        ]\n",
      " [0.01384475 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.02208098 0.00490314 0.01307683 ... 0.00852632 0.         0.        ]\n",
      " [0.03235241 0.00735471 0.01961524 ... 0.01278947 0.         0.        ]\n",
      " [0.0566806  0.00980628 0.02615365 ... 0.01705263 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Item-based collaborative filtering using cosine similarity\n",
    "item_similarity_matrix = cosine_similarity(np.nan_to_num(train_matrix.T, nan=0))\n",
    "predicted_matrix_item_based = np.dot(np.nan_to_num(train_matrix, nan=0), item_similarity_matrix) / (np.sum(item_similarity_matrix, axis=1) + 1e-9)\n",
    "\n",
    "# Print the first 5 rows of item-based predicted matrix\n",
    "print(f\"Item-based predicted matrix (first 5 rows):\")\n",
    "print(predicted_matrix_item_based[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc22ebd8-e178-4781-8928-c91d536b8ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User similarity matrix (first 5 rows):\n",
      "[[1.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         1.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.22486277 0.22487355 0.22485937]\n",
      " [0.         0.         0.06805382 ... 0.3026123  0.30262681 0.30260773]\n",
      " [0.         0.         0.07233372 ... 0.32164357 0.32165899 0.32163871]]\n",
      "User-based predicted matrix (first 5 rows):\n",
      "[[3.48269093e+01 0.00000000e+00 1.09081103e-02 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.58465400e+01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.98661375e+02 3.80454790e-03 2.32024919e-02 ... 8.24239841e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.98231189e+02 3.80080035e-03 2.31796370e-02 ... 8.23427950e-03\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.96519015e+02 3.78628592e-03 2.30911190e-02 ... 8.20283457e-03\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# User-based collaborative filtering using cosine similarity\n",
    "user_similarity_matrix = cosine_similarity(np.nan_to_num(train_matrix, nan=0))\n",
    "\n",
    "# Calculate predicted ratings for the user-based approach\n",
    "predicted_matrix_user_based = np.dot(user_similarity_matrix, np.nan_to_num(train_matrix, nan=0))\n",
    "\n",
    "# Normalize the predictions by dividing by the sum of similarities\n",
    "user_similarity_sum = np.sum(np.abs(user_similarity_matrix), axis=1)\n",
    "predicted_matrix_user_based /= (user_similarity_sum[:, np.newaxis] + 1e-9)  # Prevent division by zero\n",
    "\n",
    "# Print the user similarity matrix and first 5 rows of predicted user-based matrix\n",
    "print(f\"User similarity matrix (first 5 rows):\")\n",
    "print(user_similarity_matrix[:5])\n",
    "\n",
    "print(f\"User-based predicted matrix (first 5 rows):\")\n",
    "print(predicted_matrix_user_based[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b238b761-c892-4386-ab65-2bffab66cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined predicted matrix (first 5 rows):\n",
      "[[ 10.46992103  33.54788938  33.95594548 ...  33.74001324  33.57802976\n",
      "   33.64806308]\n",
      " [ 41.2347823   33.41738296  33.94172484 ...  33.85287046  33.39435623\n",
      "   33.78876824]\n",
      " [151.02454903  33.37138188  34.11862019 ...  33.41043244  33.11305379\n",
      "   33.19266657]\n",
      " [151.5719831   33.48442076  32.69135936 ...  33.55924911  33.68332132\n",
      "   33.3093229 ]\n",
      " [151.75982318  33.45134178  33.19338898 ...  33.42009238  34.03042835\n",
      "   33.26821293]]\n"
     ]
    }
   ],
   "source": [
    "# Combine SVD and user-based predictions\n",
    "predicted_matrix = 0.7 * predicted_matrix_svd + 0.3 * predicted_matrix_user_based  # Emphasis on SVD for higher-order patterns\n",
    "\n",
    "# Print combined prediction matrix sample\n",
    "print(f\"Combined predicted matrix (first 5 rows):\")\n",
    "print(predicted_matrix[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9d33b01-8f80-4776-8c56-e4bd8b92dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 3.50\n",
      "Best F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Validate and Fine-Tune Threshold for F1\n",
    "best_f1, best_threshold = 0, 3.5  # Starting threshold for positive ratings\n",
    "thresholds = np.arange(3.0, 4.5, 0.1)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    valid_actual, valid_predicted = [], []\n",
    "\n",
    "    for i, j in valid_indices:\n",
    "        if not np.isnan(train_matrix[i, j]):\n",
    "            valid_actual.append(train_matrix[i, j] >= threshold)\n",
    "            valid_predicted.append(predicted_matrix[i, j] >= threshold)\n",
    "\n",
    "    # Check if valid_actual or valid_predicted is empty\n",
    "    if valid_actual and valid_predicted:\n",
    "        f1 = f1_score(valid_actual, valid_predicted)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_threshold = f1, threshold\n",
    "\n",
    "# Print the best threshold and F1 score\n",
    "print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "print(f\"Best F1 Score: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4116a29-d16f-4ad0-9bc7-453c518e167b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.7021\n"
     ]
    }
   ],
   "source": [
    "# Apply best threshold to test data for final F1\n",
    "test_actual, test_predicted = [], []\n",
    "\n",
    "for i, j in test_indices:\n",
    "    if not np.isnan(ratings_matrix[i, j]):\n",
    "        test_actual.append(ratings_matrix[i, j] >= best_threshold)\n",
    "        test_predicted.append(predicted_matrix[i, j] >= best_threshold)\n",
    "\n",
    "# Handle zero division issue\n",
    "f1_test = f1_score(test_actual, test_predicted, zero_division=1)\n",
    "\n",
    "# Print final F1 score for test data\n",
    "print(f\"Test F1 Score: {f1_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "853dac3e-a087-446d-ad4b-52af658dadfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar users for User 0:\n",
      "User 443 with similarity score: 0.5654\n",
      "User 5 with similarity score: 0.5550\n",
      "User 548 with similarity score: 0.3380\n",
      "User 527 with similarity score: 0.2715\n",
      "User 21 with similarity score: 0.2013\n"
     ]
    }
   ],
   "source": [
    "# Function to find top 5 similar users\n",
    "def top_5_similar_users(user_id, user_similarity_matrix):\n",
    "    similar_users = user_similarity_matrix[user_id]\n",
    "    top_5_users = np.argsort(similar_users)[::-1][1:6]  # Exclude the user itself\n",
    "    return top_5_users, similar_users[top_5_users]\n",
    "\n",
    "# Test for User 0 (can be changed to any user)\n",
    "user_id = 0\n",
    "top_users, scores = top_5_similar_users(user_id, user_similarity_matrix)\n",
    "\n",
    "# Print top 5 similar users\n",
    "print(f\"Top 5 similar users for User {user_id}:\")\n",
    "for i, score in zip(top_users, scores):\n",
    "    print(f\"User {i} with similarity score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a62d9986-3533-4bec-91bf-9f2718dde0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended courses for User 345:\n",
      "Course 2508 with predicted rating: 11.3420 and actual rating: Not rated\n",
      "Course 2689 with predicted rating: 7.3089 and actual rating: Not rated\n",
      "Course 1711 with predicted rating: 6.6083 and actual rating: Not rated\n",
      "Course 4362 with predicted rating: 6.5660 and actual rating: Not rated\n",
      "Course 639 with predicted rating: 6.5579 and actual rating: Not rated\n"
     ]
    }
   ],
   "source": [
    "def recommend_courses(user_id, train_matrix, item_similarity_matrix, top_n=5):\n",
    "    # Get the ratings of the user for all courses\n",
    "    user_ratings = train_matrix[user_id]\n",
    "    \n",
    "    # Calculate the predicted ratings for all courses for the user\n",
    "    predicted_ratings = np.dot(item_similarity_matrix, np.nan_to_num(train_matrix[user_id], nan=0)) / (np.sum(item_similarity_matrix, axis=1) + 1e-9)\n",
    "    \n",
    "    # Get the predicted ratings for this specific user\n",
    "    user_predicted_ratings = predicted_ratings\n",
    "    \n",
    "    # Get the indices of the top N recommended courses (excluding courses the user has already rated)\n",
    "    recommended_courses = np.argsort(user_predicted_ratings)[::-1]  # Sort in descending order of predicted ratings\n",
    "    recommended_courses = [course for course in recommended_courses if np.isnan(user_ratings[course])][:top_n]\n",
    "    \n",
    "    # Get the actual ratings for the recommended courses\n",
    "    actual_ratings = [user_ratings[course] for course in recommended_courses]\n",
    "    \n",
    "    return recommended_courses, user_predicted_ratings[recommended_courses], actual_ratings\n",
    "\n",
    "# Test for User 0 (can be changed to any user)\n",
    "user_id = 345\n",
    "top_courses, scores, actual_ratings = recommend_courses(user_id, train_matrix, item_similarity_matrix, top_n=5)\n",
    "\n",
    "# Print the top recommended courses with their predicted and actual ratings\n",
    "print(f\"Top 5 recommended courses for User {user_id}:\")\n",
    "for i, (score, actual) in zip(top_courses, zip(scores, actual_ratings)):\n",
    "    print(f\"Course {i} with predicted rating: {score:.4f} and actual rating: {actual if not np.isnan(actual) else 'Not rated'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bafb4f2-8fb2-4862-877d-273e6526d7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
